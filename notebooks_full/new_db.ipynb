{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm\n",
    "#import pandas as pd\n",
    "import mysql.connector\n",
    "import codecs\n",
    "codecs.register(lambda name: codecs.lookup('utf8') if name == 'utf8mb4' else None)\n",
    "import conllu\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd='password',\n",
    "  #database=\"small_commits_db\"\n",
    "  database='commits_db',\n",
    "  charset='utf8mb4')\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd='password',\n",
    "  database='pruned_commits_db2',\n",
    "  charset='utf8mb4')\n",
    "\n",
    "cur = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for line in open('frequency_dict_no_pos_proc.csv'):\n",
    "    if k == 0:\n",
    "        k += 1\n",
    "    else:\n",
    "        row = line.strip().split('\\t')\n",
    "        if row[0].isalpha():\n",
    "            nmbrs = [int(i) for i in row[1:]]\n",
    "            #print(len(nmbrs))\n",
    "            try:\n",
    "                cur.execute('INSERT INTO lemmas (lemma) VALUES (%s)', (row[0],))\n",
    "            except:\n",
    "                pass\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_dict = {}\n",
    "cur.execute('SELECT * FROM lemmas')\n",
    "for i in cur.fetchall():\n",
    "    lemma_dict[i[1]] = i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = {}\n",
    "seen = set()\n",
    "k = 0\n",
    "for line in open('frequency_dict_no_pos_proc.csv'):\n",
    "    if k == 0:\n",
    "        k += 1\n",
    "    else:\n",
    "        row = line.strip().split('\\t')\n",
    "        if row[0].isalpha() and row[0] not in seen and row[0] in lemma_dict:\n",
    "            seen.add(row[0])\n",
    "            nmbrs = [int(i) for i in row[1:]]\n",
    "            #print(len(nmbrs))\n",
    "            cur.execute('INSERT INTO frequency_dict \\\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)',\n",
    "                       [lemma_dict[row[0]]]+nmbrs)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_dict = {}\n",
    "grammar_count = 0\n",
    "\n",
    "lex_gr_pair = {}\n",
    "lex_gr_count = 0\n",
    "\n",
    "langs = {}\n",
    "cur.execute('SELECT id, language_name FROM languages')\n",
    "for i in cur.fetchall():\n",
    "    langs[i[1]] = i[0]\n",
    "\n",
    "repos = set()\n",
    "mycursor.execute('SELECT gh_id, language FROM R')\n",
    "for i in mycursor.fetchall():\n",
    "    if i[1] in langs:\n",
    "        repos.add(i[0])\n",
    "\n",
    "lemma_dict = {}\n",
    "cur.execute('SELECT * FROM lemmas')\n",
    "for i in cur.fetchall():\n",
    "    lemma_dict[i[1]] = i[0]\n",
    "\n",
    "len(repos), len(lemma_dict)\n",
    "\n",
    "user_dict = {}\n",
    "mycursor.execute('SELECT id, login FROM U')\n",
    "for i in mycursor.fetchall():\n",
    "    user_dict[i[1]] = i[0]\n",
    "\n",
    "relations = {}\n",
    "cur.execute('SELECT id, relation_name FROM relations')\n",
    "for i in cur.fetchall():\n",
    "    relations[i[1]] = i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_gr(feats):\n",
    "    try:\n",
    "        return '|'.join('='.join(i) for i in feats.items())\n",
    "    except AttributeError:\n",
    "        return ''\n",
    "\n",
    "def yield_c():\n",
    "    mycursor.execute('SELECT * FROM C;')\n",
    "    item = mycursor.fetchone()\n",
    "    #print (text)\n",
    "    while item:\n",
    "        yield item\n",
    "        item = mycursor.fetchone()\n",
    "\n",
    "example_count = 0\n",
    "\n",
    "def parse_doc(item, global_key):\n",
    "    global grammar_count, lex_gr_count, example_count, lemma_dict, grammar_dict, lex_gr_pair\n",
    "    text = item[3]\n",
    "    date = item[4][:10]\n",
    "    if item[2] in repos and item[1] in user_dict:\n",
    "        user = user_dict[item[1]]\n",
    "        repo = item[2]\n",
    "        doc = conllu.parse(item[-1])\n",
    "        new_doc = []\n",
    "        example_used = False\n",
    "        to_append = []\n",
    "        for sentence in doc:\n",
    "            snt = [None]\n",
    "            for token in sentence.tokens:\n",
    "                if token['lemma'] in lemma_dict:\n",
    "                    gram_str = unify_gr(token['feats'])\n",
    "                    upos = token['upostag']\n",
    "                    if (gram_str, upos,) in grammar_dict:\n",
    "                        gram = grammar_dict[(gram_str, upos,)]\n",
    "                    else:\n",
    "                        cur.execute('INSERT INTO grammar (string_format, pos) VALUES (%s, %s)', (gram_str, upos,))\n",
    "                        grammar_count += 1\n",
    "                        gram = grammar_count\n",
    "                        grammar_dict[(gram_str, upos,)] = gram\n",
    "\n",
    "                    lemma = lemma_dict[token['lemma']]\n",
    "                    if (lemma, gram,) not in lex_gr_pair:\n",
    "                        cur.execute('INSERT INTO lemma_grammar_pairs (id_lemma, id_grammar, form) \\\n",
    "                        VALUES (%s, %s, %s)', (lemma, gram, token['form'].lower()))\n",
    "                        lex_gr_count += 1\n",
    "                        lex_gr_pair[(lemma, gram, )] = lex_gr_count\n",
    "                    lg = lex_gr_pair[(lemma, gram,)]\n",
    "                    snt.append((lemma, gram, lg, token['deprel'], token['head']))\n",
    "                else:\n",
    "                    snt.append(None)\n",
    "            for key, token in enumerate(snt):\n",
    "                if key > 0:\n",
    "                    if token != None:\n",
    "                        if snt[token[4]] is not None:\n",
    "                            idx = snt[token[4]][2]\n",
    "                            if not example_used:\n",
    "                                cur.execute('INSERT INTO examples \\\n",
    "                                            (text, id_user, id_repo, date) \\\n",
    "                                            VALUES (%s, %s, %s, %s)', (text, user, repo, date,))\n",
    "                                example_used = True\n",
    "                                example_count += 1\n",
    "                                example = example_count\n",
    "                            diff = token[4]-key\n",
    "                            if diff > 0: diff = min(diff, 126)\n",
    "                            else: diff = max(diff, -126)\n",
    "                            to_append.append((idx, token[2], relations[token[3]], example, diff),)\n",
    "        cur.executemany('INSERT INTO relation_pair \\\n",
    "        (id_head, id_dependent, id_relation, id_example, idx_diff) \\\n",
    "        VALUES (%s, %s, %s, %s, %s)', to_append)\n",
    "    if global_key % 1000 == 0:\n",
    "        db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_gr_count_dict = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_gr(feats):\n",
    "    try:\n",
    "        return '|'.join('='.join(i) for i in feats.items())\n",
    "    except AttributeError:\n",
    "        return ''\n",
    "\n",
    "def yield_c():\n",
    "    mycursor.execute('SELECT * FROM C;')\n",
    "    item = mycursor.fetchone()\n",
    "    #print (text)\n",
    "    while item:\n",
    "        yield item\n",
    "        item = mycursor.fetchone()\n",
    "\n",
    "example_count = 0\n",
    "\n",
    "def parse_doc(item, global_key):\n",
    "    global grammar_count, lex_gr_count, example_count, lemma_dict, grammar_dict, lex_gr_pair\n",
    "    text = item[3]\n",
    "    date = item[4][:10]\n",
    "    if item[2] in repos and item[1] in user_dict:\n",
    "        user = user_dict[item[1]]\n",
    "        repo = item[2]\n",
    "        doc = conllu.parse(item[-1])\n",
    "        new_doc = []\n",
    "        example_used = False\n",
    "        to_append = []\n",
    "        for sentence in doc:\n",
    "            snt = [None]\n",
    "            for token in sentence.tokens:\n",
    "                if token['lemma'] in lemma_dict:\n",
    "                    gram_str = unify_gr(token['feats'])\n",
    "                    upos = token['upostag']\n",
    "                    if (gram_str, upos,) in grammar_dict:\n",
    "                        gram = grammar_dict[(gram_str, upos,)]\n",
    "                    else:\n",
    "                        cur.execute('INSERT INTO grammar (string_format, pos) VALUES (%s, %s)', (gram_str, upos,))\n",
    "                        grammar_count += 1\n",
    "                        gram = grammar_count\n",
    "                        grammar_dict[(gram_str, upos,)] = gram\n",
    "\n",
    "                    lemma = lemma_dict[token['lemma']]\n",
    "                    if (lemma, gram,) not in lex_gr_pair:\n",
    "                        cur.execute('INSERT INTO lemma_grammar_pairs (id_lemma, id_grammar, form) \\\n",
    "                        VALUES (%s, %s, %s)', (lemma, gram, token['form'].lower()))\n",
    "                        lex_gr_count += 1\n",
    "                        lex_gr_pair[(lemma, gram, )] = lex_gr_count\n",
    "                    lg = lex_gr_pair[(lemma, gram,)]\n",
    "                    lex_gr_count_dict[(lemma, gram,)]+=1\n",
    "                    snt.append((lemma, gram, lg, token['deprel'], token['head']))\n",
    "                else:\n",
    "                    snt.append(None)\n",
    "            for key, token in enumerate(snt):\n",
    "                if key > 0:\n",
    "                    if token != None:\n",
    "                        if snt[token[4]] is not None:\n",
    "                            idx = snt[token[4]][0]\n",
    "                            if not example_used:\n",
    "                                cur.execute('INSERT INTO examples \\\n",
    "                                            (text, id_user, id_repo, date) \\\n",
    "                                            VALUES (%s, %s, %s, %s)', (text, user, repo, date,))\n",
    "                                example_used = True\n",
    "                                example_count += 1\n",
    "                                example = example_count\n",
    "                            diff = token[4]-key\n",
    "                            if diff > 0: diff = min(diff, 126)\n",
    "                            else: diff = max(diff, -126)\n",
    "                            to_append.append((idx, token[0], relations[token[3]], example, diff),)\n",
    "        cur.executemany('INSERT INTO relation_pair \\\n",
    "        (id_head, id_dependent, id_relation, id_example, idx_diff) \\\n",
    "        VALUES (%s, %s, %s, %s, %s)', to_append)\n",
    "    if global_key % 1000 == 0:\n",
    "        db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('DELETE FROM relation_pair')\n",
    "cur.execute('ALTER TABLE relation_pair AUTO_INCREMENT = 1 ;')\n",
    "cur.execute('DELETE FROM lemma_grammar_pairs')\n",
    "cur.execute('ALTER TABLE lemma_grammar_pairs AUTO_INCREMENT = 1 ;')\n",
    "cur.execute('DELETE FROM grammar')\n",
    "cur.execute('ALTER TABLE grammar AUTO_INCREMENT = 1 ;')\n",
    "cur.execute('DELETE FROM examples')\n",
    "cur.execute('ALTER TABLE examples AUTO_INCREMENT = 1 ;')\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4373a8352f3547ef863417085dad3e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for key, item in tqdm(enumerate(yield_c())): \n",
    "    try:\n",
    "        parse_doc(item, key) \n",
    "    except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404717, 404717)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lex_gr_count_dict), len(lex_gr_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5178, 60) 51702\n",
      "(5178, 60) 39\n"
     ]
    }
   ],
   "source": [
    "for key in lex_gr_pair:\n",
    "    print(key, lex_gr_pair[key])\n",
    "    break\n",
    "for key in lex_gr_count_dict:\n",
    "    print(key, lex_gr_count_dict[key])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for key in lex_gr_pair:\n",
    "    data.append((lex_gr_count_dict[key], lex_gr_pair[key],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(39, 51702),\n",
       " (33, 196299),\n",
       " (3, 278001),\n",
       " (9, 184875),\n",
       " (1, 183253),\n",
       " (1, 358498),\n",
       " (5, 35800),\n",
       " (1, 307273),\n",
       " (8, 367695),\n",
       " (2, 193726)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18798193"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx = 0\n",
    "for i in data:\n",
    "    mx = max(mx, i[0])\n",
    "mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.executemany('UPDATE lemma_grammar_pairs SET totalcount=%s WHERE id=%s', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_gr_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in yield_c():\n",
    "    data = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    for key, item in tqdm(enumerate(yield_c())): \n",
    "        parse_doc(item) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f parse_doc parse_doc(data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## id_lgp to id_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm\n",
    "#import pandas as pd\n",
    "import mysql.connector\n",
    "import codecs\n",
    "codecs.register(lambda name: codecs.lookup('utf8') if name == 'utf8mb4' else None)\n",
    "import conllu\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd='password',\n",
    "  #database=\"small_commits_db\"\n",
    "  database='pruned_commits_db2',\n",
    "  charset='utf8mb4')\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd='password',\n",
    "  database='pruned_commits_db2',\n",
    "  charset='utf8mb4')\n",
    "\n",
    "cur = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_c():\n",
    "    mycursor.execute('SELECT id_head, id_relation, id_dependent, id_example, idx_diff FROM relation_pair')\n",
    "    item = mycursor.fetchmany(1000)\n",
    "    #print (text)\n",
    "    while item:\n",
    "        yield item\n",
    "        item = mycursor.fetchmany(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('DELETE FROM examples_bi')\n",
    "cur.execute('ALTER TABLE examples_bi AUTO_INCREMENT = 1 ;')\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77659e00ab5c4596b38b94f9998c9d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rel_pairs = {}\n",
    "counter = 0\n",
    "data = []\n",
    "for key, batch in tqdm(enumerate(yield_c())): \n",
    "    for item in batch:\n",
    "        try:\n",
    "            if item[:3] not in rel_pairs:\n",
    "                counter += 1\n",
    "                rel_pairs[item[:3]] = counter\n",
    "            data.append((rel_pairs[item[:3]], item[3], item[4],))\n",
    "        except Exception as e: print(e)\n",
    "    if key % 100 == 0:\n",
    "        cur.executemany('INSERT INTO examples_bi (id_rel_pair, id_example, idx_diff) VALUES (%s, %s, %s)', data)\n",
    "        db.commit()\n",
    "        data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29965515"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rel_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10fb7b204afa4408b15bf492341a6531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for key, value in tqdm(enumerate(sorted(rel_pairs, key=rel_pairs.get))):\n",
    "    if key % 100000 == 0:\n",
    "        cur.executemany('INSERT INTO aggr_rel_pairs (id, id_head, id_relation, id_dependent) \\\n",
    "                                            VALUES (%s, %s, %s, %s)', data)\n",
    "        db.commit()\n",
    "        data = []\n",
    "    else:\n",
    "        data.append((rel_pairs[value], *value,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.executemany('INSERT INTO aggr_rel_pairs (id, id_head, id_relation, id_dependent) \\\n",
    "                                            VALUES (%s, %s, %s, %s)', data)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_re():\n",
    "    mycursor.execute('SELECT id_rel_pair FROM examples_bi')\n",
    "    item = mycursor.fetchmany(1000)\n",
    "    #print (text)\n",
    "    while item:\n",
    "        yield item\n",
    "        item = mycursor.fetchmany(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ebb706436324fa8880d7931fa185619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rel_pairs = defaultdict(int)\n",
    "for key, batch in tqdm(enumerate(yield_re())): \n",
    "    for item in batch:\n",
    "        rel_pairs[item[0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff04d627518e4d0399b92654b3277335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for key, value in tqdm(enumerate(sorted(rel_pairs))):\n",
    "    if key % 100000 == 0:\n",
    "        cur.executemany('UPDATE aggr_rel_pairs SET total_count=%s WHERE id=%s', data)\n",
    "        db.commit()\n",
    "        data = []\n",
    "    else:\n",
    "        data.append((rel_pairs[value], value, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.executemany('UPDATE aggr_rel_pairs SET total_count=%s WHERE id=%s', data)\n",
    "db.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
