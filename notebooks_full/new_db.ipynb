{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm\n",
    "#import pandas as pd\n",
    "import mysql.connector\n",
    "import codecs\n",
    "codecs.register(lambda name: codecs.lookup('utf8') if name == 'utf8mb4' else None)\n",
    "import conllu\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd='password',\n",
    "  #database=\"small_commits_db\"\n",
    "  database='commits_db',\n",
    "  charset='utf8mb4')\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd='password',\n",
    "  database='pruned_commits_db',\n",
    "  charset='utf8mb4')\n",
    "\n",
    "cur = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for line in open('frequency_dict_no_pos_proc.csv'):\n",
    "    if k == 0:\n",
    "        k += 1\n",
    "    else:\n",
    "        row = line.strip().split('\\t')\n",
    "        if row[0].isalpha():\n",
    "            nmbrs = [int(i) for i in row[1:]]\n",
    "            #print(len(nmbrs))\n",
    "            try:\n",
    "                cur.execute('INSERT INTO lemmas (lemma) VALUES (%s)', (row[0],))\n",
    "            except:\n",
    "                pass\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_dict = {}\n",
    "cur.execute('SELECT * FROM lemmas')\n",
    "for i in cur.fetchall():\n",
    "    lemma_dict[i[1]] = i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = {}\n",
    "seen = set()\n",
    "k = 0\n",
    "for line in open('frequency_dict_no_pos_proc.csv'):\n",
    "    if k == 0:\n",
    "        k += 1\n",
    "    else:\n",
    "        row = line.strip().split('\\t')\n",
    "        if row[0].isalpha() and row[0] not in seen and row[0] in lemma_dict:\n",
    "            seen.add(row[0])\n",
    "            nmbrs = [int(i) for i in row[1:]]\n",
    "            #print(len(nmbrs))\n",
    "            cur.execute('INSERT INTO frequency_dict \\\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)',\n",
    "                       [lemma_dict[row[0]]]+nmbrs)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_dict = {}\n",
    "grammar_count = 0\n",
    "\n",
    "lex_gr_pair = {}\n",
    "lex_gr_count = 0\n",
    "\n",
    "langs = {}\n",
    "cur.execute('SELECT id, language_name FROM languages')\n",
    "for i in cur.fetchall():\n",
    "    langs[i[1]] = i[0]\n",
    "\n",
    "repos = set()\n",
    "cur.execute('SELECT gh_id, language FROM repos')\n",
    "for i in cur.fetchall():\n",
    "    if i[1] in langs:\n",
    "        repos.add(i[0])\n",
    "\n",
    "lemma_dict = {}\n",
    "cur.execute('SELECT * FROM lemmas')\n",
    "for i in cur.fetchall():\n",
    "    lemma_dict[i[1]] = i[0]\n",
    "\n",
    "len(repos), len(lemma_dict)\n",
    "\n",
    "user_dict = {}\n",
    "cur.execute('SELECT id, login FROM users')\n",
    "for i in cur.fetchall():\n",
    "    user_dict[i[1]] = i[0]\n",
    "\n",
    "relations = {}\n",
    "cur.execute('SELECT id, relation_name FROM relations')\n",
    "for i in cur.fetchall():\n",
    "    relations[i[1]] = i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_gr(feats):\n",
    "    try:\n",
    "        return '|'.join('='.join(i) for i in feats.items())\n",
    "    except AttributeError:\n",
    "        return ''\n",
    "\n",
    "def yield_c():\n",
    "    mycursor.execute('SELECT * FROM C;')\n",
    "    item = mycursor.fetchone()\n",
    "    #print (text)\n",
    "    while item:\n",
    "        yield item\n",
    "        item = mycursor.fetchone()\n",
    "\n",
    "example_count = 0\n",
    "\n",
    "def parse_doc(item, global_key):\n",
    "    global grammar_count, lex_gr_count, example_count, lemma_dict, grammar_dict, lex_gr_pair\n",
    "    text = item[3]\n",
    "    date = item[4][:10]\n",
    "    if item[2] in repos and item[1] in user_dict:\n",
    "        user = user_dict[item[1]]\n",
    "        repo = item[2]\n",
    "        doc = conllu.parse(item[-1])\n",
    "        new_doc = []\n",
    "        example_used = False\n",
    "        to_append = []\n",
    "        for sentence in doc:\n",
    "            snt = [None]\n",
    "            for token in sentence.tokens:\n",
    "                if token['lemma'] in lemma_dict:\n",
    "                    gram_str = unify_gr(token['feats'])\n",
    "                    upos = token['upostag']\n",
    "                    if (gram_str, upos,) in grammar_dict:\n",
    "                        gram = grammar_dict[(gram_str, upos,)]\n",
    "                    else:\n",
    "                        cur.execute('INSERT INTO grammar (string_format, pos) VALUES (%s, %s)', (gram_str, upos,))\n",
    "                        grammar_count += 1\n",
    "                        gram = grammar_count\n",
    "                        grammar_dict[(gram_str, upos,)] = gram\n",
    "\n",
    "                    lemma = lemma_dict[token['lemma']]\n",
    "                    if (lemma, gram,) not in lex_gr_pair:\n",
    "                        cur.execute('INSERT INTO lemma_grammar_pairs (id_lemma, id_grammar, form) \\\n",
    "                        VALUES (%s, %s, %s)', (lemma, gram, token['form'].lower()))\n",
    "                        lex_gr_count += 1\n",
    "                        lex_gr_pair[(lemma, gram, )] = lex_gr_count\n",
    "                    lg = lex_gr_pair[(lemma, gram,)]\n",
    "                    snt.append((lemma, gram, lg, token['deprel'], token['head']))\n",
    "                else:\n",
    "                    snt.append(None)\n",
    "            for key, token in enumerate(snt):\n",
    "                if key > 0:\n",
    "                    if token != None:\n",
    "                        if snt[token[4]] is not None:\n",
    "                            idx = snt[token[4]][2]\n",
    "                            if not example_used:\n",
    "                                cur.execute('INSERT INTO examples \\\n",
    "                                            (text, id_user, id_repo, date) \\\n",
    "                                            VALUES (%s, %s, %s, %s)', (text, user, repo, date,))\n",
    "                                example_used = True\n",
    "                                example_count += 1\n",
    "                                example = example_count\n",
    "                            diff = token[4]-key\n",
    "                            if diff > 0: diff = min(diff, 126)\n",
    "                            else: diff = max(diff, -126)\n",
    "                            to_append.append((idx, token[2], relations[token[3]], example, diff),)\n",
    "        cur.executemany('INSERT INTO relation_pair \\\n",
    "        (id_head, id_dependent, id_relation, id_example, idx_diff) \\\n",
    "        VALUES (%s, %s, %s, %s, %s)', to_append)\n",
    "    if global_key % 1000 == 0:\n",
    "        db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('DELETE FROM relation_pair')\n",
    "cur.execute('ALTER TABLE relation_pair AUTO_INCREMENT = 1 ;')\n",
    "cur.execute('DELETE FROM lemma_grammar_pairs')\n",
    "cur.execute('ALTER TABLE lemma_grammar_pairs AUTO_INCREMENT = 1 ;')\n",
    "cur.execute('DELETE FROM grammar')\n",
    "cur.execute('ALTER TABLE grammar AUTO_INCREMENT = 1 ;')\n",
    "cur.execute('DELETE FROM examples')\n",
    "cur.execute('ALTER TABLE examples AUTO_INCREMENT = 1 ;')\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa91ad2d504c46e287d4be4ef8cb01f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for key, item in tqdm(enumerate(yield_c())): \n",
    "    try:\n",
    "        parse_doc(item, key) \n",
    "    except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in yield_c():\n",
    "    data = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    for key, item in tqdm(enumerate(yield_c())): \n",
    "        parse_doc(item) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f parse_doc parse_doc(data, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
