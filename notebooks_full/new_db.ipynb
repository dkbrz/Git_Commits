{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm\n",
    "#import pandas as pd\n",
    "import mysql.connector\n",
    "import codecs\n",
    "codecs.register(lambda name: codecs.lookup('utf8') if name == 'utf8mb4' else None)\n",
    "import conllu\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd='password',\n",
    "  #database=\"small_commits_db\"\n",
    "  database='commits_db',\n",
    "  charset='utf8mb4')\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd='password',\n",
    "  database='pruned_commits_db2',\n",
    "  charset='utf8mb4')\n",
    "\n",
    "cur = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for line in open('frequency_dict_no_pos_proc.csv'):\n",
    "    if k == 0:\n",
    "        k += 1\n",
    "    else:\n",
    "        row = line.strip().split('\\t')\n",
    "        if row[0].isalpha():\n",
    "            nmbrs = [int(i) for i in row[1:]]\n",
    "            #print(len(nmbrs))\n",
    "            try:\n",
    "                cur.execute('INSERT INTO lemmas (lemma) VALUES (%s)', (row[0],))\n",
    "            except:\n",
    "                pass\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_dict = {}\n",
    "cur.execute('SELECT * FROM lemmas')\n",
    "for i in cur.fetchall():\n",
    "    lemma_dict[i[1]] = i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = {}\n",
    "seen = set()\n",
    "k = 0\n",
    "for line in open('frequency_dict_no_pos_proc.csv'):\n",
    "    if k == 0:\n",
    "        k += 1\n",
    "    else:\n",
    "        row = line.strip().split('\\t')\n",
    "        if row[0].isalpha() and row[0] not in seen and row[0] in lemma_dict:\n",
    "            seen.add(row[0])\n",
    "            nmbrs = [int(i) for i in row[1:]]\n",
    "            #print(len(nmbrs))\n",
    "            cur.execute('INSERT INTO frequency_dict \\\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)',\n",
    "                       [lemma_dict[row[0]]]+nmbrs)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_dict = {}\n",
    "grammar_count = 0\n",
    "\n",
    "lex_gr_pair = {}\n",
    "lex_gr_count = 0\n",
    "\n",
    "langs = {}\n",
    "cur.execute('SELECT id, language_name FROM languages')\n",
    "for i in cur.fetchall():\n",
    "    langs[i[1]] = i[0]\n",
    "\n",
    "repos = set()\n",
    "mycursor.execute('SELECT gh_id, language FROM R')\n",
    "for i in mycursor.fetchall():\n",
    "    if i[1] in langs:\n",
    "        repos.add(i[0])\n",
    "\n",
    "lemma_dict = {}\n",
    "cur.execute('SELECT * FROM lemmas')\n",
    "for i in cur.fetchall():\n",
    "    lemma_dict[i[1]] = i[0]\n",
    "\n",
    "len(repos), len(lemma_dict)\n",
    "\n",
    "user_dict = {}\n",
    "mycursor.execute('SELECT id, login FROM U')\n",
    "for i in mycursor.fetchall():\n",
    "    user_dict[i[1]] = i[0]\n",
    "\n",
    "relations = {}\n",
    "cur.execute('SELECT id, relation_name FROM relations')\n",
    "for i in cur.fetchall():\n",
    "    relations[i[1]] = i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_gr(feats):\n",
    "    try:\n",
    "        return '|'.join('='.join(i) for i in feats.items())\n",
    "    except AttributeError:\n",
    "        return ''\n",
    "\n",
    "def yield_c():\n",
    "    mycursor.execute('SELECT * FROM C;')\n",
    "    item = mycursor.fetchone()\n",
    "    #print (text)\n",
    "    while item:\n",
    "        yield item\n",
    "        item = mycursor.fetchone()\n",
    "\n",
    "example_count = 0\n",
    "\n",
    "def parse_doc(item, global_key):\n",
    "    global grammar_count, lex_gr_count, example_count, lemma_dict, grammar_dict, lex_gr_pair\n",
    "    text = item[3]\n",
    "    date = item[4][:10]\n",
    "    if item[2] in repos and item[1] in user_dict:\n",
    "        user = user_dict[item[1]]\n",
    "        repo = item[2]\n",
    "        doc = conllu.parse(item[-1])\n",
    "        new_doc = []\n",
    "        example_used = False\n",
    "        to_append = []\n",
    "        for sentence in doc:\n",
    "            snt = [None]\n",
    "            for token in sentence.tokens:\n",
    "                if token['lemma'] in lemma_dict:\n",
    "                    gram_str = unify_gr(token['feats'])\n",
    "                    upos = token['upostag']\n",
    "                    if (gram_str, upos,) in grammar_dict:\n",
    "                        gram = grammar_dict[(gram_str, upos,)]\n",
    "                    else:\n",
    "                        cur.execute('INSERT INTO grammar (string_format, pos) VALUES (%s, %s)', (gram_str, upos,))\n",
    "                        grammar_count += 1\n",
    "                        gram = grammar_count\n",
    "                        grammar_dict[(gram_str, upos,)] = gram\n",
    "\n",
    "                    lemma = lemma_dict[token['lemma']]\n",
    "                    if (lemma, gram,) not in lex_gr_pair:\n",
    "                        cur.execute('INSERT INTO lemma_grammar_pairs (id_lemma, id_grammar, form) \\\n",
    "                        VALUES (%s, %s, %s)', (lemma, gram, token['form'].lower()))\n",
    "                        lex_gr_count += 1\n",
    "                        lex_gr_pair[(lemma, gram, )] = lex_gr_count\n",
    "                    lg = lex_gr_pair[(lemma, gram,)]\n",
    "                    snt.append((lemma, gram, lg, token['deprel'], token['head']))\n",
    "                else:\n",
    "                    snt.append(None)\n",
    "            for key, token in enumerate(snt):\n",
    "                if key > 0:\n",
    "                    if token != None:\n",
    "                        if snt[token[4]] is not None:\n",
    "                            idx = snt[token[4]][2]\n",
    "                            if not example_used:\n",
    "                                cur.execute('INSERT INTO examples \\\n",
    "                                            (text, id_user, id_repo, date) \\\n",
    "                                            VALUES (%s, %s, %s, %s)', (text, user, repo, date,))\n",
    "                                example_used = True\n",
    "                                example_count += 1\n",
    "                                example = example_count\n",
    "                            diff = token[4]-key\n",
    "                            if diff > 0: diff = min(diff, 126)\n",
    "                            else: diff = max(diff, -126)\n",
    "                            to_append.append((idx, token[2], relations[token[3]], example, diff),)\n",
    "        cur.executemany('INSERT INTO relation_pair \\\n",
    "        (id_head, id_dependent, id_relation, id_example, idx_diff) \\\n",
    "        VALUES (%s, %s, %s, %s, %s)', to_append)\n",
    "    if global_key % 1000 == 0:\n",
    "        db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_gr_count_dict = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_gr(feats):\n",
    "    try:\n",
    "        return '|'.join('='.join(i) for i in feats.items())\n",
    "    except AttributeError:\n",
    "        return ''\n",
    "\n",
    "def yield_c():\n",
    "    mycursor.execute('SELECT * FROM C;')\n",
    "    item = mycursor.fetchone()\n",
    "    #print (text)\n",
    "    while item:\n",
    "        yield item\n",
    "        item = mycursor.fetchone()\n",
    "\n",
    "example_count = 0\n",
    "\n",
    "def parse_doc(item, global_key):\n",
    "    global grammar_count, lex_gr_count, example_count, lemma_dict, grammar_dict, lex_gr_pair\n",
    "    text = item[3]\n",
    "    date = item[4][:10]\n",
    "    if item[2] in repos and item[1] in user_dict:\n",
    "        user = user_dict[item[1]]\n",
    "        repo = item[2]\n",
    "        doc = conllu.parse(item[-1])\n",
    "        new_doc = []\n",
    "        example_used = False\n",
    "        to_append = []\n",
    "        for sentence in doc:\n",
    "            snt = [None]\n",
    "            for token in sentence.tokens:\n",
    "                if token['lemma'] in lemma_dict:\n",
    "                    gram_str = unify_gr(token['feats'])\n",
    "                    upos = token['upostag']\n",
    "                    if (gram_str, upos,) in grammar_dict:\n",
    "                        gram = grammar_dict[(gram_str, upos,)]\n",
    "                    else:\n",
    "                        cur.execute('INSERT INTO grammar (string_format, pos) VALUES (%s, %s)', (gram_str, upos,))\n",
    "                        grammar_count += 1\n",
    "                        gram = grammar_count\n",
    "                        grammar_dict[(gram_str, upos,)] = gram\n",
    "\n",
    "                    lemma = lemma_dict[token['lemma']]\n",
    "                    if (lemma, gram,) not in lex_gr_pair:\n",
    "                        cur.execute('INSERT INTO lemma_grammar_pairs (id_lemma, id_grammar, form) \\\n",
    "                        VALUES (%s, %s, %s)', (lemma, gram, token['form'].lower()))\n",
    "                        lex_gr_count += 1\n",
    "                        lex_gr_pair[(lemma, gram, )] = lex_gr_count\n",
    "                    lg = lex_gr_pair[(lemma, gram,)]\n",
    "                    lex_gr_count_dict[(lemma, gram,)]+=1\n",
    "                    snt.append((lemma, gram, lg, token['deprel'], token['head']))\n",
    "                else:\n",
    "                    snt.append(None)\n",
    "            for key, token in enumerate(snt):\n",
    "                if key > 0:\n",
    "                    if token != None:\n",
    "                        if snt[token[4]] is not None:\n",
    "                            idx = snt[token[4]][0]\n",
    "                            if not example_used:\n",
    "                                cur.execute('INSERT INTO examples \\\n",
    "                                            (text, id_user, id_repo, date) \\\n",
    "                                            VALUES (%s, %s, %s, %s)', (text, user, repo, date,))\n",
    "                                example_used = True\n",
    "                                example_count += 1\n",
    "                                example = example_count\n",
    "                            diff = token[4]-key\n",
    "                            if diff > 0: diff = min(diff, 126)\n",
    "                            else: diff = max(diff, -126)\n",
    "                            to_append.append((idx, token[0], relations[token[3]], example, diff),)\n",
    "        cur.executemany('INSERT INTO relation_pair \\\n",
    "        (id_head, id_dependent, id_relation, id_example, idx_diff) \\\n",
    "        VALUES (%s, %s, %s, %s, %s)', to_append)\n",
    "    if global_key % 1000 == 0:\n",
    "        db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('DELETE FROM relation_pair')\n",
    "cur.execute('ALTER TABLE relation_pair AUTO_INCREMENT = 1 ;')\n",
    "cur.execute('DELETE FROM lemma_grammar_pairs')\n",
    "cur.execute('ALTER TABLE lemma_grammar_pairs AUTO_INCREMENT = 1 ;')\n",
    "cur.execute('DELETE FROM grammar')\n",
    "cur.execute('ALTER TABLE grammar AUTO_INCREMENT = 1 ;')\n",
    "cur.execute('DELETE FROM examples')\n",
    "cur.execute('ALTER TABLE examples AUTO_INCREMENT = 1 ;')\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4373a8352f3547ef863417085dad3e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, item in tqdm(enumerate(yield_c())): \n",
    "    try:\n",
    "        parse_doc(item, key) \n",
    "    except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in yield_c():\n",
    "    data = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    for key, item in tqdm(enumerate(yield_c())): \n",
    "        parse_doc(item) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f parse_doc parse_doc(data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## id_lgp to id_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd='password',\n",
    "  #database=\"small_commits_db\"\n",
    "  database='pruned_commits_db',\n",
    "  charset='utf8mb4')\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "db = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd='password',\n",
    "  database='pruned_commits_db',\n",
    "  charset='utf8mb4')\n",
    "\n",
    "cur = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_gr_pair = {}\n",
    "cur.execute('SELECT id, id_lemma FROM lemma_grammar_pairs')\n",
    "for i in cur.fetchall():\n",
    "    lex_gr_pair[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404740"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lex_gr_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_c():\n",
    "    mycursor.execute('SELECT id_head, id_dependent, id FROM relation_pair')\n",
    "    item = mycursor.fetchone()\n",
    "    #print (text)\n",
    "    while item:\n",
    "        yield item\n",
    "        item = mycursor.fetchone()\n",
    "\n",
    "def parse_one(item):\n",
    "    global data\n",
    "    new_head = lex_gr_pair[item[0]]\n",
    "    new_dep = lex_gr_pair[item[1]]\n",
    "    new_idx = item[2]\n",
    "    if new_idx % 10000 == 0:\n",
    "        cur.executemany('UPDATE relation_pair SET id_head=%s, id_dependent=%s WHERE id=%s', data)\n",
    "        db.commit()\n",
    "        data = []\n",
    "        print('|')\n",
    "    else:\n",
    "        data.append((new_head, new_dep, new_idx,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074d0135391b48ceb9a1ea5cc452dd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n",
      "|\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a53ecb349416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mparse_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-667f094d6e74>\u001b[0m in \u001b[0;36mparse_one\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnew_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutemany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UPDATE relation_pair SET id_head=%s, id_dependent=%s WHERE id=%s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mysql/connector/cursor.py\u001b[0m in \u001b[0;36mexecutemany\u001b[0;34m(self, operation, seq_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rows\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_have_unread_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mysql/connector/cursor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmd_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterfaceError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_have_next_result\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=W0212\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mysql/connector/connection.py\u001b[0m in \u001b[0;36mcmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_cmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mServerCmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUERY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_have_next_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mysql/connector/connection.py\u001b[0m in \u001b[0;36m_handle_result\u001b[0;34m(self, packet)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterfaceError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Empty response'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpacket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_ok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpacket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m251\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mPY2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/mysql/connector/connection.py\u001b[0m in \u001b[0;36m_handle_ok\u001b[0;34m(self, packet)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpacket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mok_pkt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_ok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_server_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mok_pkt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status_flag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mok_pkt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpacket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for key, item in tqdm(enumerate(yield_c())): \n",
    "    try:\n",
    "        parse_one(item) \n",
    "    except Exception as e: print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
